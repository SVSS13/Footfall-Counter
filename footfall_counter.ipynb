{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7a4e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV: 4.12.0\n"
     ]
    }
   ],
   "source": [
    "# If needed (uncomment):\n",
    "# %pip install ultralytics opencv-python numpy pandas pyyaml\n",
    "\n",
    "import os, math, yaml, cv2, pathlib, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"OpenCV:\", cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ca80044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing roi_config.yaml\n"
     ]
    }
   ],
   "source": [
    "# üîÅ Set your own paths here\n",
    "VIDEO_PATH  = './input.mp4'            # <-- change to your actual video\n",
    "CFG_PATH    = './roi_config.yaml'      # will be created below if missing\n",
    "OUT_VIDEO   = './output_footfall.mp4'\n",
    "EVENTS_CSV  = './events_humans.csv'\n",
    "SUMMARY_CSV = './summary_humans.csv'\n",
    "SNAPS_DIR   = './events_snaps'\n",
    "\n",
    "# One-time: create a default roi_config.yaml if it doesn't exist\n",
    "if not os.path.exists(CFG_PATH):\n",
    "    default_cfg = {\n",
    "        'global': {\n",
    "            'model_weights': 'yolov8n.pt',\n",
    "            'resize_width': 960,           # None to keep original width\n",
    "            'conf_thresh': 0.35,\n",
    "            'iou_thresh': 0.45,\n",
    "            'min_confidence': 0.35,\n",
    "            'process_every_nth_frame': 1,  # >1 to skip frames for speed\n",
    "            'min_track_age': 2,\n",
    "            'cooldown_frames': 18,\n",
    "            'min_normal_pixels': 18,\n",
    "            'hysteresis_margin_pct': 25\n",
    "        },\n",
    "        'rois': {\n",
    "            'N':  {'height_pct': 8},\n",
    "            'NE': {'height_pct': 8},\n",
    "            'E':  {'height_pct': 8},\n",
    "            'SE': {'height_pct': 8},\n",
    "            'S':  {'height_pct': 8},\n",
    "            'SW': {'height_pct': 8},\n",
    "            'W':  {'height_pct': 8},\n",
    "            'NW': {'height_pct': 8}\n",
    "        }\n",
    "    }\n",
    "    with open(CFG_PATH, 'w', encoding='utf-8') as f:\n",
    "        yaml.safe_dump(default_cfg, f, sort_keys=False)\n",
    "    print(\"Created default roi_config.yaml\")\n",
    "else:\n",
    "    print(\"Using existing roi_config.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef1731f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Robust YAML loader (Windows)\n",
    "# -----------------------------\n",
    "def load_cfg(path='./roi_config.yaml'):\n",
    "    encodings_to_try = ['utf-8', 'utf-8-sig', 'cp1252', 'latin-1']\n",
    "    last_err = None\n",
    "    for enc in encodings_to_try:\n",
    "        try:\n",
    "            with open(path, 'r', encoding=enc, errors='strict') as f:\n",
    "                text = f.read()\n",
    "            text = (text\n",
    "                    .replace('\\u201c', '\"').replace('\\u201d', '\"')\n",
    "                    .replace('\\u2018', \"'\").replace('\\u2019', \"'\")\n",
    "                    .replace('\\u2013', '-').replace('\\u2014', '-'))\n",
    "            return yaml.safe_load(text)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    with open(path, 'rb') as f:\n",
    "        raw = f.read()\n",
    "    text = raw.decode('utf-8', errors='ignore')\n",
    "    try:\n",
    "        return yaml.safe_load(text)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Could not load YAML even after fallback: {e}\")\n",
    "        raise last_err\n",
    "\n",
    "# -------------------------------\n",
    "# Path-safe video opener + probe\n",
    "# -------------------------------\n",
    "def open_video(path):\n",
    "    p = str(pathlib.Path(path).expanduser().resolve())\n",
    "    cap = cv2.VideoCapture(p, cv2.CAP_FFMPEG)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(p)\n",
    "    if not cap.isOpened():\n",
    "        raise FileNotFoundError(f\"Cannot open video at: {p}\")\n",
    "    return cap\n",
    "\n",
    "def probe_video(cap, label):\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    FPS = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    N = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if W == 0 or H == 0:\n",
    "        raise RuntimeError(f\"{label}: video opened but has 0x0 size ‚Äî likely unsupported codec. Re-encode to H.264 MP4.\")\n",
    "    print(f\"[Video] {label} | {W}x{H} | {FPS:.2f} FPS | {N} frames\")\n",
    "    return W, H, FPS, N\n",
    "\n",
    "# -------------------------------\n",
    "# Direction & band helpers\n",
    "# -------------------------------\n",
    "def angle_to_dir(angle_deg):\n",
    "    ang = (angle_deg + 360.0) % 360.0\n",
    "    bins = [(0,'E'), (45,'NE'), (90,'N'), (135,'NW'), (180,'W'), (225,'SW'), (270,'S'), (315,'SE'), (360,'E')]\n",
    "    for i in range(len(bins)-1):\n",
    "        if bins[i][0] <= ang < bins[i+1][0]:\n",
    "            return bins[i][1]\n",
    "    return 'E'\n",
    "\n",
    "def build_auto_band(direction, W, H):\n",
    "    if direction in ['N','S']:\n",
    "        y = H // 2\n",
    "        return [(0, y), (W-1, y)]\n",
    "    if direction in ['E','W']:\n",
    "        x = W // 2\n",
    "        return [(x, 0), (x, H-1)]\n",
    "    if direction in ['NE','SW']:\n",
    "        return [(0, H-1), (W-1, 0)]\n",
    "    if direction in ['NW','SE']:\n",
    "        return [(W-1, H-1), (0, 0)]\n",
    "    return [(0, H//2), (W-1, H//2)]\n",
    "\n",
    "def band_to_rects(centerline, height, margin, W, H):\n",
    "    (x1,y1),(x2,y2) = centerline\n",
    "    dx, dy = (x2-x1), (y2-y1)\n",
    "    L = math.hypot(dx, dy) + 1e-6\n",
    "    nx, ny = -dy/L, dx/L  # unit normal (perp)\n",
    "    half = height/2\n",
    "    inner_half = max(1, half - margin)\n",
    "    outer_half = half + margin\n",
    "\n",
    "    def clip(x,y):\n",
    "        return int(np.clip(x, 0, W-1)), int(np.clip(y, 0, H-1))\n",
    "\n",
    "    pts_inner = np.array([\n",
    "        clip(x1 + nx*inner_half, y1 + ny*inner_half),\n",
    "        clip(x2 + nx*inner_half, y2 + ny*inner_half),\n",
    "        clip(x2 - nx*inner_half, y2 - ny*inner_half),\n",
    "        clip(x1 - nx*inner_half, y1 - ny*inner_half),\n",
    "    ])\n",
    "    pts_outer = np.array([\n",
    "        clip(x1 + nx*outer_half, y1 + ny*outer_half),\n",
    "        clip(x2 + nx*outer_half, y2 + ny*outer_half),\n",
    "        clip(x2 - nx*outer_half, y2 - ny*outer_half),\n",
    "        clip(x1 - nx*outer_half, y1 - ny*outer_half),\n",
    "    ])\n",
    "\n",
    "    ix1, iy1 = pts_inner.min(axis=0); ix2, iy2 = pts_inner.max(axis=0)\n",
    "    ox1, oy1 = pts_outer.min(axis=0); ox2, oy2 = pts_outer.max(axis=0)\n",
    "\n",
    "    inner_rect = (int(ix1), int(iy1), int(ix2), int(iy2))\n",
    "    outer_rect = (int(ox1), int(oy1), int(ox2), int(oy2))\n",
    "    return inner_rect, outer_rect, (nx, ny)\n",
    "\n",
    "def point_in_rect(pt, rect):\n",
    "    x,y = pt; x1,y1,x2,y2 = rect\n",
    "    return (x1 <= x <= x2) and (y1 <= y <= y2)\n",
    "\n",
    "def resolve_height(roi_entry, W, H):\n",
    "    if isinstance(roi_entry.get('height', None), (int, float)):\n",
    "        return int(roi_entry['height'])\n",
    "    hpct = roi_entry.get('height_pct', None)\n",
    "    if hpct is None:\n",
    "        hpct = 8\n",
    "    return max(2, int(round((float(hpct) / 100.0) * min(W, H))))\n",
    "\n",
    "def resolve_margin(global_cfg, band_height):\n",
    "    if isinstance(global_cfg.get('hysteresis_margin', None), (int, float)):\n",
    "        return int(global_cfg['hysteresis_margin'])\n",
    "    mpct = global_cfg.get('hysteresis_margin_pct', 25)\n",
    "    return max(1, int(round((float(mpct) / 100.0) * band_height)))\n",
    "\n",
    "def project_to_segment(px, py, x1, y1, x2, y2):\n",
    "    dx, dy = (x2 - x1), (y2 - y1)\n",
    "    L2 = dx*dx + dy*dy + 1e-9\n",
    "    t = ((px - x1)*dx + (py - y1)*dy) / L2\n",
    "    t_clamped = max(0.0, min(1.0, t))\n",
    "    projx = x1 + t_clamped * dx\n",
    "    projy = y1 + t_clamped * dy\n",
    "    return projx, projy, t_clamped\n",
    "\n",
    "def draw_segment_hist(frame, hist_in, hist_out, x=20, y=140, w=300, h=60):\n",
    "    bins = len(hist_in)\n",
    "    if bins == 0: return\n",
    "    bw = max(1, w // bins)\n",
    "    maxv = max(1, max(hist_in + hist_out))\n",
    "    # IN top half (green), OUT bottom half (yellow-ish)\n",
    "    for i,v in enumerate(hist_in):\n",
    "        bh = int((h//2) * (v / maxv))\n",
    "        cv2.rectangle(frame, (x + i*bw, y + (h//2 - bh)), (x + (i+1)*bw - 2, y + h//2 - 2), (0,180,0), -1)\n",
    "    for i,v in enumerate(hist_out):\n",
    "        bh = int((h//2) * (v / maxv))\n",
    "        cv2.rectangle(frame, (x + i*bw, y + h//2 + 2), (x + (i+1)*bw - 2, y + h//2 + 2 + bh), (0,255,255), -1)\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), (255,255,255), 1)\n",
    "    cv2.putText(frame, \"ROI segment histogram  (IN top, OUT bottom)\", (x, y-6),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), 1)\n",
    "    \n",
    "# -------- Single-line ROI helpers --------\n",
    "def dir_unit(label):\n",
    "    vecs = {\n",
    "        'E': (1,0), 'NE': (1,-1), 'N': (0,-1), 'NW': (-1,-1),\n",
    "        'W': (-1,0), 'SW': (-1,1), 'S': (0,1), 'SE': (1,1)\n",
    "    }\n",
    "    vx, vy = vecs.get(label, (1,0))\n",
    "    L = math.hypot(vx, vy) or 1.0\n",
    "    return (vx/L, vy/L)\n",
    "\n",
    "def unit_perp(x1, y1, x2, y2):\n",
    "    dx, dy = (x2-x1), (y2-y1)\n",
    "    L = math.hypot(dx, dy) or 1.0\n",
    "    # perpendicular to line (tangent=[dx,dy]), normal = [-dy, dx]\n",
    "    return (-dy/L, dx/L)\n",
    "\n",
    "def compute_aligned_normal(centerline, chosen_dir):\n",
    "    (x1,y1),(x2,y2) = centerline\n",
    "    nx, ny = unit_perp(x1,y1,x2,y2)\n",
    "    ux, uy = dir_unit(chosen_dir)        # desired IN direction\n",
    "    # flip normal so it points roughly along desired flow\n",
    "    if nx*ux + ny*uy < 0:\n",
    "        nx, ny = -nx, -ny\n",
    "    return (nx, ny)\n",
    "\n",
    "def signed_distance_to_line(px, py, x1, y1, nx, ny):\n",
    "    # signed distance of point P to infinite line passing through (x1,y1) with normal n\n",
    "    return (px - x1)*nx + (py - y1)*ny\n",
    "\n",
    "def draw_centerline(frame, centerline, color=(255,255,0), thickness=2):\n",
    "    (x1,y1),(x2,y2) = centerline\n",
    "    cv2.line(frame, (int(x1),int(y1)), (int(x2),int(y2)), color, thickness)\n",
    "\n",
    "def project_to_segment(px, py, x1, y1, x2, y2):\n",
    "    dx, dy = (x2 - x1), (y2 - y1)\n",
    "    L2 = dx*dx + dy*dy + 1e-9\n",
    "    t = ((px - x1)*dx + (py - y1)*dy) / L2\n",
    "    t_clamped = max(0.0, min(1.0, t))\n",
    "    projx = x1 + t_clamped * dx\n",
    "    projy = y1 + t_clamped * dy\n",
    "    return projx, projy, t_clamped\n",
    "# -------- 8-dir single-line helpers --------\n",
    "DIRECTIONS = ['N','NE','E','SE','S','SW','W','NW']\n",
    "\n",
    "def dir_unit(label):\n",
    "    vecs = {\n",
    "        'E': (1,0), 'NE': (1,-1), 'N': (0,-1), 'NW': (-1,-1),\n",
    "        'W': (-1,0), 'SW': (-1,1), 'S': (0,1), 'SE': (1,1)\n",
    "    }\n",
    "    vx, vy = vecs.get(label, (1,0))\n",
    "    L = math.hypot(vx, vy) or 1.0\n",
    "    return (vx/L, vy/L)\n",
    "\n",
    "def unit_perp(x1, y1, x2, y2):\n",
    "    dx, dy = (x2-x1), (y2-y1)\n",
    "    L = math.hypot(dx, dy) or 1.0\n",
    "    # normal perpendicular to line (tangent=[dx,dy]) is [-dy, dx]\n",
    "    return (-dy/L, dx/L)\n",
    "\n",
    "def compute_aligned_normal(centerline, chosen_dir):\n",
    "    (x1,y1),(x2,y2) = centerline\n",
    "    nx, ny = unit_perp(x1,y1,x2,y2)\n",
    "    ux, uy = dir_unit(chosen_dir)        # intended \"IN\" direction\n",
    "    # flip normal so +normal points along desired flow\n",
    "    if nx*ux + ny*uy < 0:\n",
    "        nx, ny = -nx, -ny\n",
    "    return (nx, ny)\n",
    "\n",
    "def signed_distance_to_line(px, py, x1, y1, nx, ny):\n",
    "    # signed distance of point P to infinite line through (x1,y1) with normal n\n",
    "    return (px - x1)*nx + (py - y1)*ny\n",
    "\n",
    "def draw_centerline(frame, centerline, color=(180,180,180), thickness=1):\n",
    "    (x1,y1),(x2,y2) = centerline\n",
    "    cv2.line(frame, (int(x1),int(y1)), (int(x2),int(y2)), color, thickness)\n",
    "\n",
    "def project_to_segment(px, py, x1, y1, x2, y2):\n",
    "    dx, dy = (x2 - x1), (y2 - y1)\n",
    "    L2 = dx*dx + dy*dy + 1e-9\n",
    "    t = ((px - x1)*dx + (py - y1)*dy) / L2\n",
    "    t_clamped = max(0.0, min(1.0, t))\n",
    "    projx = x1 + t_clamped * dx\n",
    "    projy = y1 + t_clamped * dy\n",
    "    return projx, projy, t_clamped\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04bdabbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Flow estimation (first seconds)\n",
    "# -------------------------------\n",
    "def estimate_dominant_direction(video_path, model, secs=6, stride=2, resize_w=None, conf=0.35, iou=0.45):\n",
    "    cap = open_video(video_path)\n",
    "    W,H,FPS,N = probe_video(cap, \"FlowProbe\")\n",
    "    n_frames = int(secs * FPS)\n",
    "    prev_centers = None\n",
    "    hist = defaultdict(int)\n",
    "    f = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok: break\n",
    "        f += 1\n",
    "        if f > n_frames: break\n",
    "        if f % stride != 0: continue\n",
    "\n",
    "        proc = frame\n",
    "        if resize_w and frame.shape[1] > resize_w:\n",
    "            s = resize_w / frame.shape[1]\n",
    "            proc = cv2.resize(frame, (resize_w, int(frame.shape[0]*s)))\n",
    "        else:\n",
    "            s = 1.0\n",
    "\n",
    "        res = model.predict(proc, classes=[0], conf=conf, iou=iou, verbose=False, device='cpu')\n",
    "        sx = frame.shape[1] / proc.shape[1]; sy = frame.shape[0] / proc.shape[0]\n",
    "        centers = []\n",
    "        if res and res[0].boxes is not None:\n",
    "            for b in res[0].boxes.xyxy.cpu().numpy():\n",
    "                x1,y1,x2,y2 = b\n",
    "                centers.append((int((x1+x2)/2*sx), int((y1+y2)/2*sy)))\n",
    "\n",
    "        if prev_centers:\n",
    "            used = set()\n",
    "            for cx,cy in centers:\n",
    "                best = None; bestd = 1e9; bestj = -1\n",
    "                for j,(px,py) in enumerate(prev_centers):\n",
    "                    if j in used: continue\n",
    "                    d = (cx-px)**2 + (cy-py)**2\n",
    "                    if d < bestd:\n",
    "                        bestd = d; best = (px,py); bestj = j\n",
    "                if best is not None and bestd < 80**2:\n",
    "                    dx,dy = cx-best[0], cy-best[1]\n",
    "                    if abs(dx)+abs(dy) >= 4:\n",
    "                        ang = math.degrees(math.atan2(-dy, dx))\n",
    "                        hist[angle_to_dir(ang)] += 1\n",
    "                    used.add(bestj)\n",
    "        prev_centers = centers\n",
    "    cap.release()\n",
    "    if not hist:\n",
    "        return 'N', (W,H), dict(hist)\n",
    "    chosen = max(hist.items(), key=lambda kv: kv[1])[0]\n",
    "    return chosen, (W,H), dict(hist)\n",
    "\n",
    "# -------------------------------\n",
    "# Custom centroid tracker with fade\n",
    "# -------------------------------\n",
    "class CentroidTracker:\n",
    "    def __init__(self, max_link=60):\n",
    "        self.max_link = max_link\n",
    "        self.next_id = 1\n",
    "        self.tracks = {}\n",
    "    def update(self, centers, bboxes, frame_idx):\n",
    "        assigned = set()\n",
    "        new_tracks = {}\n",
    "        for tid,data in self.tracks.items():\n",
    "            px,py = data['center']\n",
    "            bestj, bestd = -1, 1e9\n",
    "            for j,(cx,cy) in enumerate(centers):\n",
    "                if j in assigned: continue\n",
    "                d = (cx-px)**2 + (cy-py)**2\n",
    "                if d < bestd:\n",
    "                    bestj, bestd = j, d\n",
    "            if bestj >= 0 and bestd <= self.max_link**2:\n",
    "                cx,cy = centers[bestj]; assigned.add(bestj)\n",
    "                bb = bboxes[bestj] if bestj < len(bboxes) else data.get('bbox', (cx-10,cy-10,cx+10,cy+10))\n",
    "                new_tracks[tid] = {\n",
    "                    'center': (cx,cy),\n",
    "                    'bbox': bb,\n",
    "                    'age': data['age'] + 1,\n",
    "                    'last_seen': frame_idx\n",
    "                }\n",
    "        for j,(cx,cy) in enumerate(centers):\n",
    "            if j in assigned: continue\n",
    "            tid = self.next_id; self.next_id += 1\n",
    "            bb = bboxes[j] if j < len(bboxes) else (cx-10,cy-10,cx+10,cy+10)\n",
    "            new_tracks[tid] = {\n",
    "                'center': (cx,cy),\n",
    "                'bbox': bb,\n",
    "                'age': 1,\n",
    "                'last_seen': frame_idx\n",
    "            }\n",
    "        self.tracks = new_tracks\n",
    "        return self.tracks\n",
    "\n",
    "def id_color(tid):\n",
    "    random.seed(int(tid) * 111)\n",
    "    r = random.randint(80,255)\n",
    "    g = random.randint(80,255)\n",
    "    b = random.randint(80,255)\n",
    "    return (b,g,r)\n",
    "\n",
    "def draw_boxes_with_fade(frame, active_tracks, fade_mem, frame_idx, fade_frames=20):\n",
    "    \"\"\"Draw regular boxes and faded memory boxes.\"\"\"\n",
    "    overlay = frame.copy()\n",
    "    active_tids = set(active_tracks.keys())\n",
    "    # Active\n",
    "    for tid, data in active_tracks.items():\n",
    "        cx, cy = data['center']\n",
    "        X1,Y1,X2,Y2 = data['bbox']\n",
    "        col = id_color(tid)\n",
    "        cv2.rectangle(overlay, (X1,Y1), (X2,Y2), col, 2)\n",
    "        cv2.circle(overlay, (cx,cy), 3, col, -1)\n",
    "        cv2.putText(overlay, f\"ID {tid}\", (X1+4, max(15,Y1-6)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, col, 2)\n",
    "        fade_mem[tid] = {'bbox': (X1,Y1,X2,Y2), 'color': col, 'last_seen': frame_idx}\n",
    "    # Faded\n",
    "    for tid, mem in list(fade_mem.items()):\n",
    "        if tid in active_tids:\n",
    "            continue\n",
    "        age_off = frame_idx - mem['last_seen']\n",
    "        if age_off <= fade_frames:\n",
    "            alpha = max(0.0, 1.0 - (age_off / float(fade_frames)))\n",
    "            X1,Y1,X2,Y2 = mem['bbox']\n",
    "            col = mem['color']\n",
    "            faded = frame.copy()\n",
    "            cv2.rectangle(faded, (X1,Y1), (X2,Y2), col, 2)\n",
    "            frame[:] = cv2.addWeighted(faded, alpha, frame, 1.0 - alpha, 0)\n",
    "        else:\n",
    "            fade_mem.pop(tid, None)\n",
    "    frame[:] = overlay\n",
    "\n",
    "# ‚úÖ Event highlighting ring (GREEN for IN, YELLOW for OUT)\n",
    "def draw_event_ring(frame, cx, cy, kind):\n",
    "    color = (0,255,0) if kind == 'IN' else (0,255,255)  # GREEN / YELLOW\n",
    "    cv2.circle(frame, (int(cx), int(cy)), 22, color, 3)\n",
    "    cv2.putText(frame, kind, (int(cx)-18, int(cy)-28),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbfc042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(video_path, cfg_path, out_video, events_csv, summary_csv):\n",
    "    cfg = load_cfg(cfg_path)\n",
    "    g = cfg['global']; rois_cfg = cfg['rois']\n",
    "    model = YOLO(g['model_weights']).to('cpu')\n",
    "\n",
    "    # 1) Probe dominant flow (for HUD & normal alignment defaults)\n",
    "    chosen_flow, (W,H), hist = estimate_dominant_direction(\n",
    "        video_path, model,\n",
    "        secs=6, stride=2, resize_w=g['resize_width'],\n",
    "        conf=g['conf_thresh'], iou=g['iou_thresh']\n",
    "    )\n",
    "    print(f\"[Auto] Dominant flow ‚âà {chosen_flow}  (hist={hist})\")\n",
    "\n",
    "    # 2) Build/resolve SINGLE LINE per each of 8 directions + aligned normal\n",
    "    DIRECTIONS = ['N','NE','E','SE','S','SW','W','NW']\n",
    "    roi_lines = {}      # dir -> dict(centerline, nx, ny, source)\n",
    "    for d in DIRECTIONS:\n",
    "        r = rois_cfg.get(d, {}) if isinstance(rois_cfg, dict) else {}\n",
    "        if r.get('band', None) is None:\n",
    "            centerline = build_auto_band(d, W, H)  # auto centerline per dir\n",
    "            source = 'auto'\n",
    "        else:\n",
    "            (x1,y1),(x2,y2) = r['band']\n",
    "            centerline = [(int(x1),int(y1)), (int(x2),int(y2))]\n",
    "            source = 'cfg'\n",
    "        nx, ny = compute_aligned_normal(centerline, d)  # +normal => \"towards d\"\n",
    "        roi_lines[d] = {'centerline': centerline, 'nx': nx, 'ny': ny, 'source': source}\n",
    "\n",
    "    # 3) Counting loop\n",
    "    cap = open_video(video_path)\n",
    "    W2,H2,FPS,N = probe_video(cap, \"Main\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(out_video, fourcc, FPS/max(1,g['process_every_nth_frame']), (W2,H2))\n",
    "\n",
    "    tracker = CentroidTracker(max_link=70)\n",
    "    frame_idx = 0\n",
    "\n",
    "    # per-track cooldown & prev signed distance per direction\n",
    "    last_event_frame = {}                # tid -> frame idx of last accepted event\n",
    "    from collections import defaultdict as dd\n",
    "    prev_signed = dd(dict)               # tid -> {dir: s_prev}\n",
    "    prev_t_along = dd(dict)              # tid -> {dir: t_prev}\n",
    "\n",
    "    # Global (center) totals\n",
    "    in_count = out_count = 0\n",
    "    events = []\n",
    "\n",
    "    # ‚úÖ Quadrant buckets\n",
    "    QUADS = ['NE','NW','SE','SW']\n",
    "    quad_counts = {q: {'IN':0, 'OUT':0} for q in QUADS}\n",
    "\n",
    "    # thresholds\n",
    "    min_normal_px = max(3, int(g.get('min_normal_pixels', 10)))\n",
    "    cooldown = int(g.get('cooldown_frames', 12))\n",
    "\n",
    "    # vis memory\n",
    "    fade_memory = {}\n",
    "    os.makedirs(SNAPS_DIR, exist_ok=True)\n",
    "    event_flash_until = {}               # tid -> frame until highlight persists\n",
    "    event_kind_mem = {}                  # tid -> 'IN'/'OUT'\n",
    "    EVENT_FLASH_FRAMES = 12\n",
    "\n",
    "    # per-direction histograms (for debugging/HUD)\n",
    "    BAND_SEGMENTS = 20\n",
    "    hist_in = {d: [0]*BAND_SEGMENTS for d in DIRECTIONS}\n",
    "    hist_out = {d: [0]*BAND_SEGMENTS for d in DIRECTIONS}\n",
    "\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok: break\n",
    "        frame_idx += 1\n",
    "        if frame_idx % max(1,g['process_every_nth_frame']) != 0:\n",
    "            out.write(frame); continue\n",
    "\n",
    "        # Inference (resize if needed)\n",
    "        proc = frame\n",
    "        if g['resize_width'] and frame.shape[1] > g['resize_width']:\n",
    "            s = g['resize_width'] / frame.shape[1]\n",
    "            proc = cv2.resize(frame, (g['resize_width'], int(frame.shape[0]*s)))\n",
    "        else:\n",
    "            s = 1.0\n",
    "\n",
    "        res = model.predict(proc, classes=[0], conf=g['conf_thresh'], iou=g['iou_thresh'],\n",
    "                            verbose=False, device='cpu')\n",
    "        sx, sy = frame.shape[1]/proc.shape[1], frame.shape[0]/proc.shape[0]\n",
    "\n",
    "        centers, bboxes = [], []\n",
    "        if res and res[0].boxes is not None:\n",
    "            data = res[0].boxes.xyxy.cpu().numpy()\n",
    "            confs = res[0].boxes.conf.cpu().numpy()\n",
    "            for (bx1,by1,bx2,by2), c in zip(data, confs):\n",
    "                if c < g['min_confidence']: continue\n",
    "                X1,Y1,X2,Y2 = int(bx1*sx), int(by1*sy), int(bx2*sx), int(by2*sy)\n",
    "                cx, cy = (X1+X2)//2, (Y1+Y2)//2\n",
    "                centers.append((cx,cy))\n",
    "                bboxes.append((X1,Y1,X2,Y2))\n",
    "\n",
    "        tracks = tracker.update(centers, bboxes, frame_idx)\n",
    "\n",
    "        # Draw all 8 lines; highlight dominant flow line\n",
    "        for d, info in roi_lines.items():\n",
    "            draw_centerline(frame, info['centerline'],\n",
    "                            color=(180,180,180) if d != chosen_flow else (255,255,0),\n",
    "                            thickness=2 if d == chosen_flow else 1)\n",
    "\n",
    "        # Draw boxes (active + fade)\n",
    "        draw_boxes_with_fade(frame, tracks, fade_memory, frame_idx, fade_frames=20)\n",
    "\n",
    "        # --- Collect candidate crossings per track across ALL 8 lines ---\n",
    "        for tid, data in tracks.items():\n",
    "            cx, cy = data['center']\n",
    "\n",
    "            # track-level cooldown\n",
    "            last_evt = last_event_frame.get(tid, -10**9)\n",
    "            if (frame_idx - last_evt) < cooldown:\n",
    "                if event_flash_until.get(tid, -1) >= frame_idx:\n",
    "                    kind = event_kind_mem.get(tid, 'IN')\n",
    "                    color = (0,255,0) if kind=='IN' else (0,255,255)\n",
    "                    cv2.circle(frame, (int(cx), int(cy)), 22, color, 2)\n",
    "                continue\n",
    "\n",
    "            candidates = []  # (score, kind, dir, seg_idx, t_now, delta_s)\n",
    "\n",
    "            for d, info in roi_lines.items():\n",
    "                (x1,y1),(x2,y2) = info['centerline']\n",
    "                nx, ny = info['nx'], info['ny']\n",
    "\n",
    "                s_now = signed_distance_to_line(cx, cy, x1, y1, nx, ny)\n",
    "                _, _, t_now = project_to_segment(cx, cy, x1, y1, x2, y2)\n",
    "\n",
    "                # seed previous if missing\n",
    "                if d not in prev_signed[tid]:\n",
    "                    prev_signed[tid][d] = s_now\n",
    "                    prev_t_along[tid][d] = t_now\n",
    "                    continue\n",
    "\n",
    "                s_prev = prev_signed[tid][d]\n",
    "                prev_signed[tid][d] = s_now\n",
    "                prev_t_along[tid][d] = t_now\n",
    "\n",
    "                # must cross the segment span (t within [0,1])\n",
    "                if not (0.0 <= t_now <= 1.0): \n",
    "                    continue\n",
    "\n",
    "                # detect sign change across zero AND enough motion along the normal\n",
    "                if s_prev == 0: \n",
    "                    continue\n",
    "                if (s_prev < 0 and s_now > 0) or (s_prev > 0 and s_now < 0):\n",
    "                    delta_s = s_now - s_prev\n",
    "                    if abs(delta_s) >= min_normal_px:\n",
    "                        is_in = (delta_s > 0)  # along +normal => IN\n",
    "                        kind = 'IN' if is_in else 'OUT'\n",
    "                        score = abs(delta_s)\n",
    "                        seg_idx = max(1, min(BAND_SEGMENTS, int(t_now * BAND_SEGMENTS) + 1))\n",
    "                        candidates.append((score, kind, d, seg_idx, t_now, delta_s))\n",
    "\n",
    "            # Commit at most ONE event (highest score) to avoid double-counts\n",
    "            if candidates:\n",
    "                candidates.sort(reverse=True, key=lambda x: x[0])\n",
    "                score, kind, d, seg_idx, t_now, delta_s = candidates[0]\n",
    "\n",
    "                # Center totals\n",
    "                if kind == 'IN': in_count += 1\n",
    "                else: out_count += 1\n",
    "\n",
    "                # ‚úÖ Quadrant totals: only for diagonal directions\n",
    "                if d in quad_counts:\n",
    "                    quad_counts[d][kind] += 1\n",
    "\n",
    "                last_event_frame[tid] = frame_idx\n",
    "                event_flash_until[tid] = frame_idx + EVENT_FLASH_FRAMES\n",
    "                event_kind_mem[tid] = kind\n",
    "\n",
    "                # Visual ring at centroid\n",
    "                color = (0,255,0) if kind=='IN' else (0,255,255)\n",
    "                cv2.circle(frame, (int(cx), int(cy)), 22, color, 3)\n",
    "                cv2.putText(frame, kind, (int(cx)-22, int(cy)-26),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "                # update per-direction histogram (optional)\n",
    "                if kind == 'IN': hist_in[d][seg_idx-1] += 1\n",
    "                else:            hist_out[d][seg_idx-1] += 1\n",
    "\n",
    "                # snapshot + log\n",
    "                snap_path = os.path.join(SNAPS_DIR, f\"ev_{len(events)+1:03d}_{kind}_{d}_f{frame_idx}.png\")\n",
    "                cv2.imwrite(snap_path, frame)\n",
    "\n",
    "                events.append({\n",
    "                    'timestamp': datetime.now().isoformat(timespec='seconds'),\n",
    "                    'track_id': tid, 'type': kind, 'roi_dir': d, 'flow_dir': chosen_flow,\n",
    "                    'frame_idx': frame_idx, 'cx': int(cx), 'cy': int(cy),\n",
    "                    't_0to1': round(float(t_now), 4), 'segment_idx': int(seg_idx),\n",
    "                    'segments_total': int(BAND_SEGMENTS),\n",
    "                    'delta_s': round(float(delta_s), 2),\n",
    "                    'snap': snap_path\n",
    "                })\n",
    "\n",
    "        # linger rings\n",
    "        for tid, data in tracks.items():\n",
    "            if event_flash_until.get(tid, -1) >= frame_idx:\n",
    "                kind = event_kind_mem.get(tid, 'IN')\n",
    "                color = (0,255,0) if kind=='IN' else (0,255,255)\n",
    "                cx, cy = data['center']\n",
    "                cv2.circle(frame, (int(cx), int(cy)), 22, color, 2)\n",
    "\n",
    "        # HUD: center totals + quadrant mini-counters\n",
    "        cv2.rectangle(frame, (10,10), (360,95), (0,0,0), -1)\n",
    "        cv2.putText(frame, f\"CENTER IN : {in_count}\",  (20, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
    "        cv2.putText(frame, f\"CENTER OUT: {out_count}\", (20, 85), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,255), 2)\n",
    "\n",
    "        # quadrant boxes (corners)\n",
    "        pad = 12\n",
    "        # NW (top-left)\n",
    "        cv2.rectangle(frame, (pad, pad+110), (pad+155, pad+170), (30,30,30), -1)\n",
    "        cv2.putText(frame, f\"NW IN:{quad_counts['NW']['IN']} OUT:{quad_counts['NW']['OUT']}\",\n",
    "                    (pad+8, pad+150), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), 1)\n",
    "        # NE (top-right)\n",
    "        cv2.rectangle(frame, (W2-155-pad, pad+110), (W2-pad, pad+170), (30,30,30), -1)\n",
    "        cv2.putText(frame, f\"NE IN:{quad_counts['NE']['IN']} OUT:{quad_counts['NE']['OUT']}\",\n",
    "                    (W2-146-pad, pad+150), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), 1)\n",
    "        # SW (bottom-left)\n",
    "        cv2.rectangle(frame, (pad, H2-60-pad), (pad+155, H2-pad), (30,30,30), -1)\n",
    "        cv2.putText(frame, f\"SW IN:{quad_counts['SW']['IN']} OUT:{quad_counts['SW']['OUT']}\",\n",
    "                    (pad+8, H2-20-pad), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), 1)\n",
    "        # SE (bottom-right)\n",
    "        cv2.rectangle(frame, (W2-155-pad, H2-60-pad), (W2-pad, H2-pad), (30,30,30), -1)\n",
    "        cv2.putText(frame, f\"SE IN:{quad_counts['SE']['IN']} OUT:{quad_counts['SE']['OUT']}\",\n",
    "                    (W2-146-pad, H2-20-pad), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), 1)\n",
    "\n",
    "        # Optional: histogram for dominant flow line only (to avoid clutter)\n",
    "        draw_segment_hist(frame, hist_in[chosen_flow], hist_out[chosen_flow], x=20, y=180, w=300, h=60)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save detailed event log\n",
    "    if events:\n",
    "        pd.DataFrame(events).to_csv(events_csv, index=False)\n",
    "\n",
    "    # Save center totals (compat)\n",
    "    pd.DataFrame([{\n",
    "        'CENTER_IN': in_count,\n",
    "        'CENTER_OUT': out_count,\n",
    "        'flow_direction': chosen_flow,\n",
    "        'multi_line': True\n",
    "    }]).to_csv(summary_csv, index=False)\n",
    "\n",
    "    # ‚úÖ Save quadrant summary as a separate CSV next to summary_csv\n",
    "    quadrant_csv = summary_csv.replace('.csv', '_quadrants.csv')\n",
    "    rows = []\n",
    "    for q in ['NW','NE','SW','SE']:\n",
    "        rows.append({'quadrant': q,\n",
    "                     'IN': quad_counts[q]['IN'],\n",
    "                     'OUT': quad_counts[q]['OUT']})\n",
    "    pd.DataFrame(rows).to_csv(quadrant_csv, index=False)\n",
    "\n",
    "    print('\\n‚úÖ Done.')\n",
    "    print(f'‚Ä¢ CENTER: IN={in_count} | OUT={out_count}')\n",
    "    print(f\"‚Ä¢ QUADRANTS: NW{quad_counts['NW']}  NE{quad_counts['NE']}  SW{quad_counts['SW']}  SE{quad_counts['SE']}\")\n",
    "    print(f\"‚Ä¢ Video : {out_video}\")\n",
    "    print(f\"‚Ä¢ Events: {events_csv}\")\n",
    "    print(f\"‚Ä¢ Summary (center): {summary_csv}\")\n",
    "    print(f\"‚Ä¢ Summary (quadrants): {quadrant_csv}\")\n",
    "    print(f\"‚Ä¢ Snapshots: {SNAPS_DIR}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "772ede52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Initializing YOLO and starting Footfall Counter...\n",
      "\n",
      "[Video] FlowProbe | 1920x1080 | 25.00 FPS | 341 frames\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîç Initializing YOLO and starting Footfall Counter...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVIDEO_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_video\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOUT_VIDEO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevents_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEVENTS_CSV\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msummary_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSUMMARY_CSV\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Show summary & sample events\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, Video\n",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(video_path, cfg_path, out_video, events_csv, summary_csv)\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(g[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_weights\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 1) Probe dominant flow (for HUD & normal alignment defaults)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m chosen_flow, (W,H), hist \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_dominant_direction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msecs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresize_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresize_width\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconf_thresh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miou_thresh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Auto] Dominant flow ‚âà \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchosen_flow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  (hist=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhist\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 2) Build/resolve SINGLE LINE per each of 8 directions + aligned normal\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m, in \u001b[0;36mestimate_dominant_direction\u001b[1;34m(video_path, model, secs, stride, resize_w, conf, iou)\u001b[0m\n\u001b[0;32m     10\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 12\u001b[0m     ok, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ok: \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     f \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"üîç Initializing YOLO and starting Footfall Counter...\\n\")\n",
    "\n",
    "run(\n",
    "    video_path=VIDEO_PATH,\n",
    "    cfg_path=CFG_PATH,\n",
    "    out_video=OUT_VIDEO,\n",
    "    events_csv=EVENTS_CSV,\n",
    "    summary_csv=SUMMARY_CSV\n",
    ")\n",
    "\n",
    "# Show summary & sample events\n",
    "from IPython.display import display, Video\n",
    "\n",
    "print(\"\\nüìä Summary Output:\")\n",
    "display(pd.read_csv(SUMMARY_CSV))\n",
    "\n",
    "if os.path.exists(EVENTS_CSV) and os.path.getsize(EVENTS_CSV) > 0:\n",
    "    print(\"\\nüßæ First few event logs:\")\n",
    "    display(pd.read_csv(EVENTS_CSV).head())\n",
    "\n",
    "print(\"\\nüé¨ Processed Video Preview:\")\n",
    "if os.path.exists(OUT_VIDEO):\n",
    "    display(Video(OUT_VIDEO, embed=True, width=640))\n",
    "else:\n",
    "    print(\"Processed video not found:\", OUT_VIDEO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9498440c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
